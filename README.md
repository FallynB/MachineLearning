# Machine Learning Algorithms

This repository contains implementations of various machine learning algorithms created as part of a Machine Learning course. Each algorithm is implemented from scratch to demonstrate understanding of the underlying concepts.
The implementations in this repository are based on the foundations and principles taught in CSCI158 PZ-01, and I would like to acknowledge and thank my professor for providing the theoretical framework and guidance that made these implementations possible.
## Algorithms Included

* **K-Nearest Neighbors (KNN)**: A simple, instance-based learning algorithm for classification.
* **Principal Component Analysis (PCA)**: A dimensionality reduction technique.
* **Decision Tree**: A tree-based model for classification with recursive feature splitting.
* **Random Forest**: An ensemble method leveraging multiple decision trees.
* **Gradient Boosting Regressor**: A boosting technique for regression problems.
* **Linear Regression**: Implementation of linear regression, including ordinary least squares.
* **Polynomial Regression**: Extension of linear regression to capture non-linear relationships.
* **Gradient Descent**: Optimization algorithm for minimizing loss functions.
* **Stochastic Gradient Descent**: A more efficient version of gradient descent.

## Repository Structure

Each algorithm is organized in its own directory

## Datasets Used

The implementations use several classic machine learning datasets:
* Iris dataset
* Wine dataset
* California Housing dataset
* Cars dataset

## Getting Started

To use these algorithms, you'll need:
* Python 3.6+
* NumPy
* Matplotlib
* scikit-learn (for dataset loading and comparison)
  
